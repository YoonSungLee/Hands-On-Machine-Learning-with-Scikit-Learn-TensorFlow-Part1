{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1장. 한눈에 보는 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nbviewer.jupyter.org/github/rickiepark/handson-ml/tree/master/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드의 내용은 Hands-On Machine Learning with Scikit-Learn & TensorFlow을 참고했음을 밝힙니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 시스템의 종류(p38)\n",
    "* 사람의 감독 하에 훈련하는 것인지 그렇지 않은 것인지(지도, 비지도, 준지도, 강화학습)\n",
    "* 실시간으로 점진적인 학습을 하는지 아닌지(온라인 학습과 배치 학습)\n",
    "* 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 훈련 데이터셋에서 과학자들처럼 패턴을 발견하여 예측 모델을 만드는지(사례 기반 학습과 모델 기반 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특성 공학(feature engineering)(p58)\n",
    "* 특성 선택(feature selection) : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택합니다.\n",
    "* 특성 추출(feature extraction) : 특성을 결합하여 더 유용한 특성을 만듭니다(차원 축소 알고리즘을 사용할 수 있습니다).\n",
    "* 새로운 데이터를 수집해 새 특성을 만듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과대적합(overfitting) 해결 방법(p60)\n",
    "* 과대적합 : 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어난다.\n",
    "* 파라미터 수가 적은 모델을 선택하거나(예를 들면 고차원 다항 모델보다 선형 모델), 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여(규제, regularization) 단순화시킵니다.\n",
    "* 훈련 데이터를 더 많이 모읍니다.\n",
    "* 훈련 데이터의 잡음을 줄입니다(예를 들면 오류 데이터 수정과 이상치 제거)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과소적합(underfitting) 해결 방법(p61)\n",
    "* 파라미터가 더 많은 강력한 모델을 선택합니다.\n",
    "* 학습 알고리즘에 더 좋은 특성을 제공합니다(특성 엔지니어링).\n",
    "* 모델의 제약을 줄입니다(예를 들면 규제 하이퍼파라미터를 감소시킵니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝(p62)\n",
    "* 머신러닝은 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것입니다.\n",
    "* 여러 종류의 머신러닝 시스템이 있습니다. 지도 학습과 비지도 학습, 배치 학습과 온라인 학습, 사례 기반 학습과 모델 기반 학습 등입니다.\n",
    "* 머신러닝 프로젝트에서는 훈련 세트에 데이터를 모아 학습 알고리즘에 주입합니다. 학습 알고리즘이 모델 기반이면 훈련 세트에 모델을 맞추기 위해 파라미터를 조정하고(즉, 훈련 세트에서 좋은 예측을 만들기 위해), 새로운 데이터에서도 좋은 예측을 만들 거라 기대합니다. 알고리즘이 사례 기반이면 샘플을 기억하는 것이 학습이고 새로운 샘플에 일반화하기 위해 유사도 측정을 사용합니다.\n",
    "* 훈련 세트가 너무 작거나, 대표성이 없는 데이터이거나, 잡음이 많고 관련 없는 특성으로 오염되어 있다면 시스템이 잘 작동하지 않습니다(엉터리가 들어가면 엉터리가 나옵니다). 마지막으로, 모델이 너무 단순하거나(과소적합된 경우) 너무 복잡하지 않아야 합니다(과대적합된 경우)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트와 검증(p62)\n",
    "* '훈련 세트(training set)'를 사용해 다양한 하이퍼파라미터로 여러 모델을 훈련시키고\n",
    "* '검증 세트(validation set)'에서 최상의 성능을 내는 모델과 하이퍼파라미터를 선택합니다.\n",
    "* 만족스러운 모델을 찾으면 일반화 오차의 추정값을 얻기 위해 '테스트 세트(test set)'로 단 한 번의 최종 테스트를 합니다.\n",
    "* 보통 데이터의 80%를 훈련에 사용하고 20%는 테스트용으로 떼어놓습니다.\n",
    "* 훈련 데이터에서 검증 세트로 너무 많은 양의 데이터를 뺏기지 않기 위해 일반적으로 '교차 검증(cross-validation) 기법'을 사용합니다. 훈련 세트를 여러 서브셋(subset)으로 나누고 각 모델을 이 서브셋의 조합으로 훈련시키고 나머지 부분으로 검증합니다. 모델과 하이퍼파라미터가 선택되면 전체 훈련 데이터를 사용하여 선택한 하이퍼파라미터로 최종 모델을 훈련시키고 테스트 세트에서 일반화 오차를 측정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:63) 여러 모델을 만든다 -> training set을 여러 서브셋으로 나눈다 -> 서로 다른 조합을 각각의 모델에 적용 -> validation set으로 cost 도출 -> 비교 -> 모델 / 하이퍼파라미터 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제(p64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 머신러닝을 어떻게 정의할 수 있나요?  \n",
    "머신러닝은 데이터로부터 학습할 수 있는 시스템을 만드는 것입니다. 학습이란 어떤 작업에서 주어진 성능 지표가 더 나아지는 것을 의미합니다.  \n",
    "<br>\n",
    "#### 2. 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지를 말해보세요.  \n",
    "명확한 해결책이 없는 복잡한 문제, 수작업으로 만든 긴 규칙 리스트를 대체하는 경우 ,변화하는 환경에 적응하는 시스템을 만드는 경우, 사람에게 통찰을 제공해야 하는 경우(예를 들면 데이터 마이닝)에 머신러닝이 도움을 줄 수 있다.  \n",
    "<br>\n",
    "#### 3. 레이블된 훈련 세트란 무엇인가요?  \n",
    "레이블된 훈련 세트는 각 샘플에 대해 원하는 정답(레이블)을 담고 있는 훈련 세트입니다.  \n",
    "<br>\n",
    "#### 4. 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요?  \n",
    "가장 일반적인 두 가지 지도 학습 문제는 회귀와 분류입니다.  \n",
    "<br>\n",
    "#### 5. 보편적인 비지도 학습 작업 네 가지는 무엇인가요?  \n",
    "보편적인 비지도 학습 문제는 군집, 시각화, 차원 축소, 연관 규칙 학습입니다.  \n",
    "<br>\n",
    "#### 6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?  \n",
    "알려지지 않은 지형을 탐험하는 로봇을 학습시키는 가장 좋은 방법은 강화 학습입니다. 이는 전형적으로 강화 학습이 다루는 유형의 문제입니다. 이 문제를 지도 학습이나 비지도 학습으로 표현하는 것도 가능하지만 일반적이지 않습니다.  \n",
    "<br>\n",
    "#### 7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?  \n",
    "만약 그룹을 어떻게 정의할지 모른다면 비슷한 고객끼리 군집으로 나누기 위해 군집 알고리즘(비지도학습)을 사용할 수 있습니다. 그러나 어떤 그룹이 있어야 할지 안다면 분류 알고리즘(지도 학습)에 각 그룹에 대한 샘플을 주입합니다. 그러면 알고리즘이 전체 고객을 이런 그룹으로 분류하게 될 것입니다.  \n",
    "<br>\n",
    "#### 8. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?  \n",
    "스팸 감지는 전형적인 지도 학습 문제입니다. 알고리즘에 많은 이메일과 이에 상응하는 레이블(스팸 혹은 스팸 아님)이 제공됩니다.  \n",
    "<br>\n",
    "#### 9. 온라인 학습 시스템이 무엇인가요?  \n",
    "온라인 학습 시스템은 배치 학습 시스템과 달리 점진적으로 학습할 수 있습니다. 이 방식은 변화하는 데이터와 자율 시스템에 빠르게 적응하고 매우 많은 양의 데이터를 훈련시킬 수 있습니다.  \n",
    "<br>\n",
    "#### 10. 외부 메모리 학습이 무엇인가요?  \n",
    "외부 메모리 알고리즘은 컴퓨터의 주메모리에 들어갈 수 없는 대용량의 데이터를 다룰 수 있습니다. 외부 메모리 학습 알고리즘은 데이터를 미니배치로 나누고 온라인 학습 기법을 사용해 학습합니다.  \n",
    "<br>\n",
    "#### 11. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?  \n",
    "인스턴스 기반 학습 시스템은 훈련 데이터를 기억하는 학습입니다. 새로운 샘플이 주어지면 유사도 측정을 사용해 학습된 샘플 중에서 가장 비슷한 것을 찾아 예측으로 사용합니다.  \n",
    "<br>\n",
    "#### 12. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나요?  \n",
    "모델은 하나 이상의 파라미터(예를 들면 선형 모델의 기울기)를 사용해 새로운 샘플이 주어지면 무엇을 예측할지 결정합니다. 학습 알고리즘은 모델이 새로운 샘플에 잘 일반화되도록 이런 파라미터들의 최적 값을 찾습니다. 하이퍼파라미터는 모델이 아니라 이런 학습 알고리즘 자체의 파라미터입니다(예를 들면 적용할 규제의 정도)  \n",
    "<br>\n",
    "#### 13. 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?  \n",
    "모델 기반 학습 알고리즘은 새로운 샘풀에 잘 일반화되기 위한 모델 파라미터의 최적 값을 찾습니다. 일반적으로 훈련 데이터에서 시스템의 예측이 얼마나 나쁜지 측정하고 모델에 규제가 있다면 모델 복잡도에 대한 페널티를 더한 비용 함수를 최소화함으로써 시스템을 훈련시킵니다. 예측을 만들려면 학습 알고리즘이 찾은 파라미터를 사용하는 모델의 예측함수에 새로운 샘플의 특성을 주입합니다.  \n",
    "<br>\n",
    "#### 14. 머신러닝의 주요 도전 과제는 무엇인가요?  \n",
    "머신러닝의 주요 도전 과제는 부족한 데이터, 낮은 데이터 품질, 대표성 없는 데이터, 무의미한 특성, 훈련 데이터에 과소적합된 과도하게 간단한 모델, 훈련 데이터에 과대적합된 과도하게 복잡한 모델 등입니다.  \n",
    "<br>\n",
    "#### 15. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘풀에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 가능한 해결책 세 가지는 무엇인가요?  \n",
    "모델이 훈련 데이터에서는 잘 작동하지만 새로운 샘풀에서는 형편없다면 이 모델은 훈련 데이터에 과대적합되었을 가능성이 높습니다(또는 매우 운이 좋은 경우만 훈련 데이터에 있는 것입니다).과대적합에 대한 해결책은 더 많은 데이터를 모으거나, 모델을 단순화하거나(간단한 알고리즘을 선택하거나, 특성이나 파라미터의 수를 줄이거나, 모델에 규제를 추가합니다), 훈련 데이터에 있는 잡음을 감소시키는 것입니다.  \n",
    "<br>\n",
    "#### 16. 테스트 세트가 무엇이고 왜 사용해야 하나요?  \n",
    "테스트 세트는 실전에 배치되기 전에 모델이 새로운 샘플에 대해 만들 일반화 오차를 추정하기 위해 사용합니다.  \n",
    "<br>\n",
    "#### 17. 검증 세트의 목적은 무엇인가요?  \n",
    "검증 세트는 모델을 비교하는 데 사용됩니다. 이를 사용해 가장 좋은 모델을 고르고 하이퍼파라미터를 튜닝합니다.  \n",
    "<br>\n",
    "#### 18. 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기나요?  \n",
    "테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 테스트 세트에 과대적합될 위험이 있고 일반화 오차는 매우 낙관적으로 측정될 것입니다(이 모델을 론칭하면 기대한 것보다 성능이 나쁠 것입니다).  \n",
    "<br>\n",
    "#### 19. 교차 검증이 무엇이고, 왜 하나의 검증 세트보다 선호하나요?  \n",
    "교차 검증은 검증 세트를 별도로 분리하지 않고(모델 선택과 하이퍼파라미터 튜닝을 위해) 모델을 비교할 수 있는 기술입니다. 이는 훈련 데이터를 최대한 활용하도록 도와줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
